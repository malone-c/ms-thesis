[["lit-review.html", "Chapter 2 Literature review 2.1 The problem of program design 2.2 Simple models 2.3 Advocating the use of Bayesian models 2.4 Advocating complex models 2.5 Literature gaps", " Chapter 2 Literature review In this chapter, I review literature relating to the core problem that I am concerned with in this thesis. I begin by discussing the general problem of inferring absence of a cryptic, incipient pest species population. In particular, I emphasise that the problem calls us to combine divergent approaches to mathematical modelling; (a) mechanistically realistic ecological modelling, and (b) statistical inference. I then discuss the body of literature of species absence and eradication models. While some of this literature is focused on inferring properties of species populations in general, I emphasise the problem of inferring extinction. I argue that there has been a shortage of elaborate models for this problem in the literature. 2.1 The problem of program design The primary problem this work is concerned with is to infer the absence of a cryptic pest species. A cryptic species is any species which is hard to detect. One example is snakes, which are small, immobile, camouflaged, and located in inaccessible habitats (see Kery (2002)). A problem that environmental managers and governors face is to determine the minimal length of time required for a surveillance program. I will refer to this problem as the problem of post-outbreak surveillance program design, or, alternatively, as the problem of program design. 2.2 Simple models In this section, I outline the standard existing approach to inferring pest absence. The simplest approach to this problem is given by McArdle (1990). Let the rarity of the species \\(p \\in [0, 1]\\) be the probability that a species is detected in any given sampling unit. (Sampling units can be arranged spatially or temporally; e.g. a survey that involves checking \\(w\\) weeks at \\(k\\) locations would have \\(wk\\) sampling units.) Then, the number of surveys in which the species is detected is given by \\(X \\sim \\mathrm{Binomial}(T, p)\\). Accordingly, the probability of not detecting the species in \\(T\\) surveys is given by \\[ \\alpha = \\Pr(X = 0) = 1 - (1 - p)^T. \\] The last formula allows us to compute any of the 3 quantities \\(\\alpha\\), \\(p\\), and \\(t\\), assuming the other two are given. Given this framework, the problem of program design becomes the following. We decide a priori what the smallest “rarity” \\(p\\) worth detecting is. McArdle supposes that if a species if sufficiently difficult to detect (while, nonetheless, \\(p &gt; 0\\)) then it cannot be considered a member of an ecological community, and therefore not worthy of being deemed “present.” Write the smallest rarity worth detecting as \\(p_0\\). Then, we choose a minimum detection probability \\(\\alpha\\) that we are willing to accept. For example, we might wish to have a chance of \\(\\alpha &gt; 0.95\\) of detecting a species, given that it is present. Then, with the above formula, we can rearrange to get the smallest number of survey units \\(T\\) such that detection probability \\(\\alpha\\) is achieved. Statisticians will recognise that the above is essentially power analysis for data modelled as identically and independently distributed Bernoulli trials. This analogy can be made more concrete. For any fixed rarity \\(p\\), we can derive the probability of observing \\(n\\) or more negative surveys. This is the p-value. We can then reject the hypothesis that there is the rarity is greater than \\(p_0\\), the rarity worth detecting. Applying the above model to the problem of program design is not straightforward. Firstly, the model is fairly restrictive. It assumes that the probability of detecting the pest population is constant over time. Secondly, in the case of pest populations, it may be difficult to determine the smallest value of \\(p\\) that is “worth” detecting. When a pest species is cryptic, the detectability (\\(p\\) in this model) can be extremely small even when the population is relatively large. Further, invasive potential of the pest may be large, so that even small populations bear a large cost to the decision maker. So far, I have discussed a general model, first proposed in McArdle (1990), for surveillance of a species in general. This model works well for a range of cases. However, for pest surveillance, this model has several limitations. Firstly, for monitoring of cryptic pest populations the minimal permissible rarity \\(p_0\\) may be arbitrarily small. For example, this may be the case if (a) a pest is extremely hard to detect, so that even moderate sized populations have low detection probability, and/or (b) pests have high invasive potential, so that even extremely small populations pose an invasive threat. However, when \\(p_0 = 0\\), the probability of non-detection is 1 at each timestep. 2.2.1 Some other models 2.3 Advocating the use of Bayesian models The problem of program design is a special case of problems where we wish to infer properties of a pest species. In this section, I discuss Bayesian approaches to the more general kind of problem. No probabilities Probabilities help decision makers No estimation for \\(p\\). For cryptic pest species, the model is even for dangerous levels of \\(p\\). No model of growth. Not suitable for arbitrarily small \\(p_0\\). There may be no \\(p_0 &gt; 0\\) that we would consider acceptable. Then, the goal is to reject \\(\\mathbb H_0: p \\leq p_0 = 0\\). The problem is that the model is that non-detections have probability \\(1\\) under the null hypothesis that \\(p_0 \\leq 0\\). I.e. the probability of detecting a member of the species is at most \\(0\\) under this setting. In other words, \\(\\alpha_n = 0\\), for any number of surveys \\(n\\). To get around this, we might choose \\(p_0\\) to be arbitrarily small. However, such a choice would be arbitrary and not motivated by scientific theory or value-judgment considerations. Also, setting \\(p_0\\) to be arbitrarily small may force us to be overly conservative. The smaller that we set \\(p_0\\), the larger the number of surveys \\(n\\) required to reject \\(\\mathbb H_0: p \\geq p_0\\). No prior information. This is related to the previous point. The above does not allow us to incorporate prior information about the rarity of the species. If we have reason to believe that the species is nearly extinct, then the above methodology may give overly conservative results. I.e. it might recommend surveying for longer than is required. 2.4 Advocating complex models As ((caley2014?)) points out, most models in the literature on the program design problem are simple and general. Their simplcity means that they are parsimonious, analytically tractable, and easy to interpret. However, these properties are bought at the cost of plausibility of the model as a description of real ecological processes, which are complex and uncertain. In general, the plausibility of a model will depend on the system that is under investigation. For a given model, the analyst may have information that will allow them to specify relatively more plausible and realistic models of the processes that govern the system. Complex examples are more difficult to find in the literature. One example is the model by Caley et al of foxes in Tasmania. 2.4.1 ABC models ABC methods, as exemplified by Caley’s model, are a promising approach. Here, I will give a brief description of the family of sampling algorithms known collectively as Approximate Bayesian Computation (ABC). In its simplest form, ABC is a form of rejection sampling. $$ $$ Intro to sampling algorithms Origin of ABC Motivation for ABC Extensions of ABC Benefits of ABC Can incorporate ABS 2.4.2 Motivation for ABC ABC is relatively recent technique for sampling in cases where traditional sampling techniques fail. Standard techniques for MCMC, such as Metropolis-Hastings and Gibbs sampling, assume that the likelihood function is known and can be easily computed. This may not be the case if, for example, computing the likelihood requires us to integrate out a latent variable, but the likelihood is not integrable with respect to that variable. 2.4.3 ABS models Agent based simulation (sometimes referred to as individual based simulation) is an approach to quantitative modelling. A key motivation for using ABS is that 2.5 Literature gaps The ABC technique is promising for the program design problem when pest species are cryptic and grow at low rates. However, so far, only one case study exists for this approach. Further, the model employed does not generalise easily. For example, the model does not fit easily for the case where The surveillance program is predictably structured The intensity of the surveillance program changes in a predictable way Data are not available to infer a probability of capture for a randomly drawn individual (i.e. an “individual capture rate”) 2.5.1 Problems with simple models I illustrate my point with reference to a recent Bayesian model. Barnes et al introduce a model with a constant rate. 2.5.2 Benefits of elaborate models Incorporate domain knowledge Use process models that are scientifically plausible Incorporate uncertainty 2.5.3 Barnes BTFOd There exists a category of cases under which the assumptions of basic model above are not plausible. In this section, I describe this category of cases, and outline why these cases cause problems for the Barnes model. Three assumptions of the above model are as follows: The growth of an incipient population can be described by a Poisson-offspring model. The probability of detecting a randomly drawn member of the population \\(p\\) is known, or can be reasonably estimated from data. 3.The population grows exponentially at a constant rate. I.e. the growth rate of the population is not random and does not change over time. When these assumptions are not met, the model may not be a realistic representation of the processes being modelled. Firstly, the Poisson-offspring distribution is most natural when all detectable individuals at time \\(t\\) are offspring of the individuals that were detected at time \\(t-1\\). However, this will not be the case if members of the population continue to be detectable after giving birth. It is not always possible to estimate a “rarity” parameter \\(p\\) from data. Recall that the rarity of a population is the probability of detecting a randomly drawn member of the population in a single survey. Thus, it depends fundamentally on the design and intensity of the survey employed. However, survey designs may vary significantly between regions, so that we cannot generalise estimates of \\(p\\). For example, suppose an environmental manager has estimated \\(p\\), under a standard, general surveillance program. However, they later suspect an outbreak has occured, and therefore wish to implement an intensified surveillance program. A concrete example of this can be seen in the case of Mediterranean fruit fly, surveillance is performed using a spatial network of surveillance units (i.e. traps) which are inspected at regular intervals. When an outbreak has occurred, or is suspected, the manager may wish to deploy additional, supplementary survey units. It may be objected that it should be possible to derive the an estimate of the rarity \\(p\\) using the probability-given-distance function \\(p_d\\). For example, we could simulate In applied contexts, the probability of capture must be estimated from data. In the case of small insect species, such as Mediterranean fruit fly, probability of capture is estimated with the aid of release-recapture experiments. Sterilised flies are released, in an area containing a standardised grid of surveillance units (traps). Then, after some time has passed, flies are counted. The resulting recapture data lends itself to two natural estimands. Firstly, there is the probability of a randomly selected fly being captured at all, given some trapping grid setup (e.g. a square grid with 400m spacing). This is essentially the “rarity” parameter discussed above. Secondly, there is the probability of a randomly selected fly being captured in a given trap, given the distance between the trap and the release location of the flies. As mentioned above the third assumption is that the population grows exponentially at a constant rate. This assumption will be unreasonable in cases where population growth is seasonally dependent, or and/or when we are uncertain about the growth rate. 2.5.4 Gaps Modelling probability of eradication when capture probability cannot be estimated or elicited. References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
