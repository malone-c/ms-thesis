[["case-study-mediterranean-fruit-fly-c.-capitata.html", "Chapter 5 Case study: Mediterranean fruit fly (C. Capitata) 5.1 Introduction 5.2 Medfly (Ceratitis capitata) 5.3 Data 5.4 Model 5.5 Priors 5.6 Likelihood 5.7 Sampling procedure 5.8 Results 5.9 Discussion 5.10 Conclusion", " Chapter 5 Case study: Mediterranean fruit fly (C. Capitata) 5.1 Introduction In the previous chapter, I proposed a model for evaluating and proposing zero-catch criteria in specific situations, for various locations, seasons, and species of fruit fly. In this chapter, I illustrate the method by applying the model to an hypothetical outbreak. Mediterranean fruit fly is chosen for its economic significance, and Adelaide is chosen because of the availability of research on trapping sensitivity performed there. The analysis is primarily illustrative. 5.2 Medfly (Ceratitis capitata) 5.2.1 Medfly are economically important Mediterranean fruit fly (Ceratitis Capitata) or medfly are a particularly salient species of tephritid fruit fly. Medflies have high invasive potential, as it can adapt to a relatively large range of climates and environments, and is known to have the capability to infest the fruits of over 300 species of plants (Ibid.). Recently, an incursion of medfly in Adelaide, South Australia, prompted a large scale eradication effort. This comprised in part of hiring 350 special-purpose staff that set over 13,000 additional traps, and collected over 350 tonnes of fruit. The scale of the response to this outbreak indicates the perceived economic significance of this fruit fly species. 5.2.2 Medfly are cryptic Medfly are very hard to detect at low levels. Monitoring for medfly is typically performed with the aid of lured traps (namely so-called Lynfield or Jackson traps). These traps are relatively ineffective for detecting medfly. For example, one study from the Adelaide metro area trapping grid found that only 0.02% of flies were recaptured from a release of 38.8 million flies. Further, medfly are known to have low dispersals across space. This means that low-lying populatons of flies may go undetected across generations. 5.3 Data 5.3.1 Zero-sighting surveillance data As mentioned above, I do not use real data to estimate parameters. Instead, I model a hypothetical situation. The situation is intended to simulate the conditions described in codes of practice for use of zero-catch criteria (see DPIPWE (2011)).The situation is as follows: We assume that at least one fly has been detected; eradication measures have since begun and then ceased; and we now proceed with intensified monitoring, while whatever population that may exist is free to grow relatively unhindered. The goal of the analysis is to infer the probability of eradication for the incipient population, given that no flies detected at any point in this period. Therefore, our “data” is a vector of zeroes, with one for each vector. Thus, the data we wish to learn from is hypothetical, or simulated. The idea is to simulate a relatively realistic scenario. We observe the outcomes of a surveillance process. The surveillance process is generated by weekly checks of traps that are deployed uniformly in a given area (more about the trapping arrangement below). It is assumed that no specimens are detected at any point in the survey period. In other words, the sum of all detected counts in the period is zero. It is assumed that general surveillance traps are spaced in a \\(400 \\times 400\\) metre grid, year round. We assume that a fly is caught at the centre of the grid (without loss of generality). Then, 16 supplementary traps are placed within a 200 metre of the location of the first detection. (See the section on trap locations below). These traps are checked weekly for 6 weeks (\\(t \\in \\{1, \\ldots, 6\\}\\)) before being removed. Following this, we continue to monitor with only the general surveillance traps. 5.3.2 Release recapture studies In the previous chapter, I briefly discussed release-recapture experiments. These are experiments involving the release of large numbers of flies into networks of standard traps. These studies give us a useful source of information about the probability of capturing a fly given distance between a fly and a trap. In cases where Bayesian models have been used, data has not been available on detection rates. For example, Caley and Barry (2014) and Keith and Spring (2013) set uninformative priors on the detection rates, and attempt to learn the detection rates from data (namely observed survey records). However, because of their global economic importance, tephritid fruit flies are relatively well studied. In particular, a number of fruit fly species have been studied with release recapture experiments. Release recapture experiments involve the release of a large number of (often sterilised) fruit flies. These studies help us to learn both the dispersal patterns and tendencies of various species of fly, but also the effectiveness of various trap types and layouts. 5.4 Model Now that I have discussed background and the data available, I turn to a detailed discussion of the model for this case. This discussion builds on the previous chapter, where the general, basic model was outlined. Here, I focus on the specific prior distributions and likelihood that are used. As in the previous chapter, the model is broken into priors and likelihood in the following way. Firstly, (1) The size of the population (number of individuals); (2) the locations of individuals and traps; and (3) number of individuals caught in traps, conditional on (1) and (2). 5.5 Priors Here, we are modelling the risk of an adverse event (namely an undetected pest invasion). In such cases, we might consider examining a worst case scenario. In this case, this could be done by specifying priors such that we assign high density to cases where (a) the growth rate is very close to zero, so that the fly population is capable of persisting at below-detectable levels indefinitely, or (b) flies are located far away from surveillance traps. Given these considerations, it should be trivial to identify worst-case scenarios where we can almost never be certain that flies are eradicated, given any length of time. However, such results are likely unreasonable, and do not accurately reflect our prior state of information. Nonetheless, I attempt to err on the side of pessimism about the while making the prior distribution as realistic as possible. 5.5.1 Population size In this case, \\(N_1\\) is the first week after the most recent fly detection. I have chosen to give \\(N_1\\) the prior distribution \\(N_1 \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda)\\), where \\(\\lambda \\sim \\mathrm{Exponential}(0.05)\\). This distribution for \\(N_1\\) is chosen as it is a discrete distribution with right skew, and a relatively large amount of mass \\(f_{N_1}(x)\\) at \\(x = 0\\), corresponding to the situation where flies are already eradicated (see (priorinitsize?)).2 Integrating out \\(\\lambda\\), \\(N_1\\) has the marginal mass \\(\\gamma / (1 + \\gamma)^{n+1}\\). Figure 5.1: Prior distribution of initial population size As for \\(N_t\\), for \\(t \\in \\{2, \\ldots, T\\}\\), I assume the Poisson branching process with exponential growth, discussed in the previous chapter. To recap, it is assumed that, for \\(t \\in \\{2, \\ldots, T\\}\\), \\(N_t \\mid N_{t-1}, R_t \\sim \\mathrm{Poisson}(N_{t-1} e^{R_t})\\). I have chosen the prior \\(R_t \\stackrel{\\text{iid}} \\sim \\mathrm N(0, 0.2)\\). The symmetry of this prior means that we are indifferent about whether the population is growing or declining. The variance has been chosen to place the vast majority of density below their estimated growth rate under optimal conditions. Medfly have been estimated to grow at 8% per day, in optimal lab conditions (Papadopoulos et al. (2002)). Under an exponential growth model this is 56% per week. This can be taken as an upper bound on the growth rate. In the wild, flies may fail to establish due to food scarcity, predation, and/or unsustainably low population density. Note that I do not allow the hyperparameters of \\(R_t\\) to vary as a function of time. This is unrealistic, as it is widely recognised that fruit fly growth rates are highly dependent on weather. In practical, applied cases, it will be desirable to attempt to estimate \\(R_t\\) from data. Therefore, if possible, fly population growth rates should be estimated conditional on weather. Choosing an empirically realistic distribution for \\(R_t\\) is likely to improve the efficiency of inference from the survey record. 5.5.2 Spatial location As mentioned in the previous chapter, the model is spatial, insofar as likelihood of detection depends on distances between traps and individual flies. 5.5.2.1 Population location The centre of of the population is assumed to be located at the two dimensional vector \\(L_c\\). I have set the prior on \\(L_c\\) to be \\[ L_c \\sim \\mathrm {Normal}_2 (\\mathbf 0_2, 160^2 I_2), \\] where \\(\\mathrm{Normal}_2\\) is the bivariate normal distribution, \\(\\mathbb 0_2\\) is the two-dimensional zero vector and \\(I_2\\) is the \\(2 \\times 2\\) identity matrix. This prior reflects a prior belief that the centre of the population is highly likely to be found somewhere on a disc with. E.g., we believe that there is a 95% chance that the centre of the population is within \\(1.96 \\cdot 160 \\approx 320\\) metres of the centre of the grid.3 Recall that this makes sense because we believe that the flies are within the distribution. 5.5.2.2 Individual fly dispersals Let \\(L_{i, t}\\) denote the location of fly \\(i\\) at time \\(t\\), as in the previous chapter. I assign this quantity the prior distribution \\[ L_{i, t} \\mid L_c \\sim \\mathrm {Normal}_2 (L_c, 12.5^2 I_2) \\] where the notation is defined as in the previous section above. The variance of this distribution is chosen on the basis of prior analysis of dispersal data (see appendix). The normal distribution is chosen for a few reasons. Firstly, it is conceptually simple and intuitive to parameterise. Secondly, the location has a simple marginal distribution, thanks to the fact that a normal random variable with a normal mean is itself normal. Thirdly, the distance between a normal random variable and its mean has a known distribution. In particular, for any fly \\(i\\), the squared distance between \\(L_{i,t}\\) and \\(L_c\\), conditional on \\(L_c\\), has the gamma distribution with parameters \\(\\alpha = 1\\), and \\(\\beta = 12.5^2 / 2\\). Similarly, the distance between \\(L_{i, t}\\) and the origin is the same but with \\(\\beta = (12.5^2 + 160^2) / 2\\). Knowing this allows us to easily compare and calibrate the distribution against experimental results. This, in turn, makes elicitation of priors simpler and more intuitive. (It allows us to visualise, for example, the distribution of distances to the origin and to the population centre.) The normal prior is chosen for convenience. There is evidence suggesting that Medfly dispersal is in fact distributed as a power law (see, e.g., Meats and Clift (2005) and Plant and Cunningham (1991)). Given this, It may be worth noting that, in real cases, the assumed prior distribution on dispersals may not be reasonable. For example, dispersals may have non-zero mean (due to strength and direction) or non-spherical covariance matrix (i.e. non-equal variances and/or non-zero covariances).4 Further, it may not be reasonable to assume that the fly population cannot move across time. Ideally, the importance of these assumptions should be checked based on the case at hand (e.g. properties of the situation or species in question). Extending the model in various ways to meet these problems is beyond the scope of this work, but warrants further investigation. 5.5.3 Trap locations Figure 5.2: Illustration of the hypothetical trapping grid. Grey circle represents 200m radius disc surrounding the site of the most most recently detected medfly specimen. As mentioned previously, it is assumed that trap locations have fixed, known locations. In particular, we assume that monitoring is intensified for the first 6 weeks (\\(t \\in \\{1, \\ldots, 6\\}\\)). By intensified monitoring, I mean that supplementary monitoring traps have been placed alongside the previously existing grid of general monitoring traps. More precisely, it is assumed that general surveillance traps are placed year round in a 400 \\(\\times\\) 400 metre grid (DPIPWE, 2011, p. 50). The supplementary surveillance system consists of a set of 16 traps in a circular area, centred at the site of the first fly detection.5 See (trapgrid?). 5.6 Likelihood 5.6.1 Probability of capture As mentioned previously, results of release-recapture studies can be used to parameterise I assume that the probability of capture for any given fly in any given trap is \\[ p(x) = \\begin{cases}ax^{-b}, &amp; d&gt;1 \\\\ a &amp; 0 \\geq d \\geq 1\\end{cases} \\] where \\(a = 0.4702111 / 2\\), \\(b = 1.37\\), and \\(x\\) is the distance between the fly and the trap at the start of the period. Thresholding is introduced because (a) the function does not yield valid probabilities for small enough \\(x\\). In general, the use of a negative exponential function is not ideal here. This function is used for convenience as it is provided by the authors of the study, and data is not publicly accessible. In the context of a more detailed analysis, it may be beneficial to consider uncertainty in the probability of capture by specifying hyperprior distributions for \\(a\\) and \\(b\\). I do not explore this further here, as the model is intended to be illustrative only. An adjustment is made to \\(p(x)\\). In \\(p(x)\\) we have the probability of capture over the lifetime of the individual. It is assumed that the lifetime is roughly 4 weeks. 5.7 Sampling procedure In this section, I discuss the problem of computing the posterior distribution, given a survey record. Above, I stated that the model could be defined flexibly. Without restrictions on the form of the growth and detection models, the posterior may be analytically intractable. In other words, we will not be able to write out the posterior density or mass as a function of the data and prior distributions. Such situations are common in the Bayesian framework, because of the tendency for the posterior density or mass to depend, implicitly or explicitly, on analytically intractable integrals. So far, we have talked about situations when sampling is required for inference. Further problems arise when the model is agent-based. In other words, when we include uncertainty about individual-level features in the model. In this case, the detection probability is random, even when the location and population size is known. In other words, the probability of detecting at least one individual is a function of the number of individuals, and also their individual (random) properties. This is a situation in which “the number of things you do not know is one of the things you do not know” (Richardson and Green, 1997). 5.7.1 Approximate Bayesian Computation A rejection algorithm is used to draw samples from the posterior distribution (see chapter 2). Instead of matching on a statistic, such as the sum of the observations, the rejection rule was set so that data were only kept in cases where the simulated data vector was an exact match with the actual data (the hypothetical zero-catch record). Here, I have used ABC for intuitiveness, ease of implementation, and the fact that it is relatively efficient for this problem. However, other methods exist that may be worth exploring, for analogous problems where the rejection rate of ABC is higher. There are at least two known methods for sampling from the posterior when the dimension of the parameter space is uncertain. These are the reversible jump MCMC sample (Green (1995)) and the generalised Gibbs sampler ((keith2015?)). These may be worth exploring for problems where the rejection rate is high for ABC. Interestingly, the standard justifications for and against ABC do not apply to the case under consideration. Firstly, the standard justification for ABC is that it allows for inference when the likelihood function is “intractable” - i.e., unknown, uncomputable or otherwise difficult to work with. However, for the current model, the likelihood is known, and relatively simple to write out. On the other hand, the standard drawback for ABC is that it ensures that we can typically only draw from the posterior approximately. Under standard conditions, we must define a criteria for similarity between simulated and observed data. This is typically done by specifying a summary statistic \\(S(\\mathbb y)\\), and a similarity measure \\(\\rho(S(\\mathbb y), S(\\mathbb y&#39;))\\) defined over the space spanning our data \\(\\mathbb y\\). We reject a sample if we observe \\(\\rho(\\mathbb y_{\\text{observed}}, \\mathbb y_{\\text{simulated}} ) &gt; \\epsilon_0\\), where \\(\\epsilon_0\\). \\(10{,}000\\) samples were taken. The acceptance rate for sampling was 0.68. This high level of acceptance is due to the low likelihood of captures, across most of the high prior density region of the model space. The acceptance rate can be interpreted as a numerical approximation to the prior probability of observing zero captures. 5.8 Results The fly free period is 12 weeks or 28 days and one generation, whichever is longer (Meats and Clift (2005)). In summer, a Medfly generation takes 28-34 days (Mediterranean fruit fly life cycle and biology (n.d.)). Therefore, the period I look at is over 12 weeks. However, this may be different based on the period that the manager is interested in. The posterior probability of extinction after 12 weeks is approximately 0.684.6 5.9 Discussion Here I discuss limitations and objections. 5.9.1 Reasons to distrust this model There may be many cases where flies are not eradicated, but the population size is unsustainably small. No uncertainty about the probability of capture. Growth rates are not weather dependent. Dispersal data is used twice. The location prior and likelihood use data from different sources. 5.9.2 Model validation 5.9.2.1 Model validation is hard for this case Cite Gelman et al on model validation. The best way to check models is to compare with other sources of data. However, we never observe the full number of flies in an outbreak. We could augment the model and use it on release-recapture data, to try and predict the number of captures. Sensitivity analysis should be performed on the following Check the assumption of no interference. Check the sensitivity to the \\(N_1\\) prior. Check the sensitivity to the assumption 5.9.3 Limitations We do not get a posterior distribution over the probability of eradication. TODO: Section on objections to/limitations of the model Objection: the model is subjective Objection: The model is too sensitive to priors. Defence in Caley 2015 Fruit sampling also occurs 5.9.4 Future work Sensitivity analysis for \\(N_1\\) Sensitivity analysis for growth rates Model checking for the growth process Estimating growth process parameters from data. 5.10 Conclusion References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
